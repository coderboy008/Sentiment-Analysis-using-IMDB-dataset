{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbcjfujq19u_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f2245f32-6da5-4260-91eb-64732f846ad0"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn import metrics\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1ogoQ9GJ5m0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('dataset.csv', encoding='latin-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA63isGu2FCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_text(text):\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
        "    return clean_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRx4uRI8YonJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b0c1cc3-b2db-41f5-8f80-2960ca59b501"
      },
      "source": [
        "print(string.punctuation)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe9Oy8ylY2MH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f3882989-204e-4972-bf06-3bf08fb6c5e5"
      },
      "source": [
        "print(stopwords.words('english'))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9VIeuuMgZ2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d067ac32-f664-4c0a-f526-0ffda2b012d4"
      },
      "source": [
        "nltk.__name__"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nltk'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6mIyogg3MSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir(nltk)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHM5KifhW69J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e3035c93-5492-4425-ff7a-db0b9c2ba4d1"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SentimentText</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>first think another Disney movie, might good, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>big fan Stephen King's work, film made even gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       SentimentText  Sentiment\n",
              "0  first think another Disney movie, might good, ...          1\n",
              "1  Put aside Dr. House repeat missed, Desperate H...          0\n",
              "2  big fan Stephen King's work, film made even gr...          1\n",
              "3  watched horrid thing TV. Needless say one movi...          0\n",
              "4  truly enjoyed film. acting terrific plot. Jeff...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkW5dhCZW9c-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "480726dd-1270-4979-dbe1-ef9aae07d4e3"
      },
      "source": [
        "data['SentimentText'].apply(process_text)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [first, think, another, Disney, movie, might, ...\n",
              "1        [Put, aside, Dr, House, repeat, missed, Desper...\n",
              "2        [big, fan, Stephen, Kings, work, film, made, e...\n",
              "3        [watched, horrid, thing, TV, Needless, say, on...\n",
              "4        [truly, enjoyed, film, acting, terrific, plot,...\n",
              "5        [memory, Last, Hunt, stuck, since, saw, 1956, ...\n",
              "6        [Shakespeare, fan, appreciate, Ken, Branagh, d...\n",
              "7        [privilege, watching, Scarface, big, screen, b...\n",
              "8        [real, classic, shipload, sailors, trying, get...\n",
              "9        [Serials, short, subjects, originally, shown, ...\n",
              "10       [strange, sex, comedy, theres, little, comedy,...\n",
              "11       [many, problems, film, worst, continuity, reed...\n",
              "12       [Rosie, wasted, lot, TV, time, talking, Tainos...\n",
              "13       [Man, people, got, chill, movie, artistic, gen...\n",
              "14       [great, movie, could, Soylent, Green, scenes, ...\n",
              "15       [Wonderful, family, dramacomedy, starring, Mac...\n",
              "16       [Ko, tamo, peva, one, best, films, ever, saw, ...\n",
              "17       [quite, long, time, life, either, like, film, ...\n",
              "18       [Kolchak, TV, series, really, didnt, fit, cate...\n",
              "19       [rare, find, literary, work, adequately, trans...\n",
              "20       [awful, awful, old, room, mate, used, watch, j...\n",
              "21       [mom, recently, become, addicted, show, laughi...\n",
              "22       [okay, plain, dumb, bad, horrorcomedy, film, r...\n",
              "23       [film, mesmerizing, beauty, creativity, artist...\n",
              "24       [Filmfour, going, lot, better, little, snot, f...\n",
              "25       [60s, 1999, Mark, Piznarski, Josh, Hamilton, J...\n",
              "26       [show, suck, Unfortunately, really, question, ...\n",
              "27       [Sometimes, want, laugh, Dont, analyzing, crit...\n",
              "28       [antibush, jokes, get, really, easy, show, lik...\n",
              "29       [others, noted, excellent, Hammerstyle, film, ...\n",
              "                               ...                        \n",
              "24970    [almost, ideal, romantic, anime, MUST, SEE, AG...\n",
              "24971    [Unfortunately, film, long, unavailable, poste...\n",
              "24972    [12, Diane, Keaton, farcebr, br, Someone, tell...\n",
              "24973    [Film, looking, glass, see, world, new, light,...\n",
              "24974    [empty, lack, lustre, rendition, classic, nove...\n",
              "24975    [movie, good, example, extreme, lack, good, wr...\n",
              "24976    [movie, really, great, flick, something, affec...\n",
              "24977    [Darkling, interesting, entertaining, film, F,...\n",
              "24978    [Marlon, Brando, Frank, Sinatra, HATED, film, ...\n",
              "24979    [2004, liked, became, stupid, suggests, kids, ...\n",
              "24980    [avoid, making, type, film, future, film, inte...\n",
              "24981    [Wow, 5, hours, Riget, Lars, continues, great,...\n",
              "24982    [Marvelous, James, Stewart, Vera, Miles, vehic...\n",
              "24983    [characters, depthless, rip, offs, youve, seen...\n",
              "24984    [countless, talkinganimal, films, past, majori...\n",
              "24985    [absurdist, dark, comedy, Belgium, Shot, perfe...\n",
              "24986    [nice, see, Suraj, Barjatya, back, best, atA, ...\n",
              "24987    [movie, poorly, written, poorly, acted, predic...\n",
              "24988    [unpretentious, Horror, film, probably, destin...\n",
              "24989    [saw, Saving, Grace, right, came, video, Since...\n",
              "24990    [Taking, old, collection, stories, poses, chal...\n",
              "24991    [movie, made, want, become, director, Michelle...\n",
              "24992    [video, thing, think, fourth, attempt, managed...\n",
              "24993    [almost, typical, Lynch, However, makes, film,...\n",
              "24994    [really, must, caught, different, film, rest, ...\n",
              "24995    [kid, 50s, 60s, anything, connected, Disney, d...\n",
              "24996    [course, reading, review, seen, film, already,...\n",
              "24997    [read, Theres, Girl, Soup, came, Peter, Seller...\n",
              "24998    [film, quite, boring, snippets, naked, flesh, ...\n",
              "24999    [Although, film, somewhat, filled, eighties, c...\n",
              "Name: SentimentText, Length: 25000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldNt-ogtKJGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "pipeline = Pipeline([\n",
        "    ('bow',CountVectorizer(analyzer=process_text)), # converts strings to integer counts\n",
        "    ('tfidf',TfidfTransformer()), # converts integer counts to weighted TF-IDF scores\n",
        "    ('classifier',MultinomialNB()) # train on TF-IDF vectors with Naive Bayes classifier\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#predictions = pipeline.predict(x_test)\n",
        "#print(predictions)\n",
        "##"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ch2owb_VDPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "75def605-3b9e-4822-ee5a-b18a33800e0f"
      },
      "source": [
        "pipeline.fit(x_train,y_train)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('bow',\n",
              "                 CountVectorizer(analyzer=<function process_text at 0x7f5b287e7048>,\n",
              "                                 binary=False, decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('classifier',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDl9hBEv4Czf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = pipeline.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BDouFVv4ao1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2aa0d867-618d-4856-dabb-0911713bc031"
      },
      "source": [
        "print(predictions)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb8PiO8TNXOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62a6b450-7247-4452-a074-380f50e955a4"
      },
      "source": [
        "print(metrics.accuracy_score(y_test,predictions))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSUsVAtLNfO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}